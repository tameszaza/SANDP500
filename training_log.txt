i = 1
threshold = 0.00299
Now training 1 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 10, 'DT__min_samples_split': 5}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 3, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 9, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 10, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 1 days prediction in the future
Now evaluating 1 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.35      0.38      0.36      1142
           0       0.41      0.46      0.44      1282
           1       0.39      0.32      0.35      1298

    accuracy                           0.39      3722
   macro avg       0.39      0.39      0.38      3722
weighted avg       0.39      0.39      0.38      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.29      0.33      1142
           0       0.43      0.49      0.46      1282
           1       0.40      0.44      0.42      1298

    accuracy                           0.41      3722
   macro avg       0.41      0.41      0.40      3722
weighted avg       0.41      0.41      0.41      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.38      0.37      0.37      1142
           0       0.43      0.45      0.44      1282
           1       0.39      0.38      0.39      1298

    accuracy                           0.40      3722
   macro avg       0.40      0.40      0.40      3722
weighted avg       0.40      0.40      0.40      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.37      0.32      0.35      1142
           0       0.41      0.61      0.49      1282
           1       0.40      0.25      0.31      1298

    accuracy                           0.40      3722
   macro avg       0.39      0.39      0.38      3722
weighted avg       0.39      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.39      0.35      0.36      1142
           0       0.45      0.48      0.46      1282
           1       0.42      0.43      0.42      1298

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.42      3722
weighted avg       0.42      0.42      0.42      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.40      0.29      0.34      1142
           0       0.43      0.55      0.48      1282
           1       0.40      0.38      0.39      1298

    accuracy                           0.41      3722
   macro avg       0.41      0.41      0.40      3722
weighted avg       0.41      0.41      0.41      3722

Now plotting 1 days prediction in the future
i = 2
threshold = 0.00396
Now training 2 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.1, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 7, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 2 days prediction in the future
Now evaluating 2 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.36      0.39      0.37      1209
           0       0.33      0.36      0.34      1060
           1       0.45      0.38      0.41      1453

    accuracy                           0.38      3722
   macro avg       0.38      0.38      0.38      3722
weighted avg       0.38      0.38      0.38      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.40      0.40      1209
           0       0.37      0.57      0.45      1060
           1       0.47      0.27      0.34      1453

    accuracy                           0.40      3722
   macro avg       0.41      0.41      0.39      3722
weighted avg       0.42      0.40      0.39      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.39      0.38      0.38      1209
           0       0.36      0.45      0.40      1060
           1       0.46      0.38      0.42      1453

    accuracy                           0.40      3722
   macro avg       0.40      0.40      0.40      3722
weighted avg       0.41      0.40      0.40      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.40      0.38      0.39      1209
           0       0.35      0.62      0.45      1060
           1       0.47      0.23      0.31      1453

    accuracy                           0.39      3722
   macro avg       0.41      0.41      0.38      3722
weighted avg       0.41      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.43      0.44      0.44      1209
           0       0.38      0.43      0.41      1060
           1       0.50      0.45      0.47      1453

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.44      0.44      0.44      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.40      0.40      0.40      1209
           0       0.39      0.55      0.45      1060
           1       0.48      0.34      0.39      1453

    accuracy                           0.42      3722
   macro avg       0.42      0.43      0.42      3722
weighted avg       0.43      0.42      0.41      3722

Now plotting 2 days prediction in the future
i = 3
threshold = 0.00491
Now training 3 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.1, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 3 days prediction in the future
Now evaluating 3 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.40      0.42      0.41      1191
           0       0.31      0.36      0.34      1010
           1       0.49      0.42      0.45      1521

    accuracy                           0.40      3722
   macro avg       0.40      0.40      0.40      3722
weighted avg       0.41      0.40      0.41      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.52      0.44      1191
           0       0.39      0.44      0.41      1010
           1       0.49      0.31      0.38      1521

    accuracy                           0.41      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.43      0.41      0.41      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.37      0.36      0.37      1191
           0       0.32      0.39      0.35      1010
           1       0.46      0.41      0.43      1521

    accuracy                           0.39      3722
   macro avg       0.39      0.39      0.38      3722
weighted avg       0.40      0.39      0.39      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.36      0.36      0.36      1191
           0       0.34      0.61      0.44      1010
           1       0.49      0.23      0.31      1521

    accuracy                           0.37      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.41      0.37      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.50      0.49      0.50      1191
           0       0.40      0.45      0.43      1010
           1       0.57      0.53      0.55      1521

    accuracy                           0.50      3722
   macro avg       0.49      0.49      0.49      3722
weighted avg       0.50      0.50      0.50      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.39      0.44      0.41      1191
           0       0.38      0.40      0.39      1010
           1       0.48      0.42      0.45      1521

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.42      3722
weighted avg       0.42      0.42      0.42      3722

Now plotting 3 days prediction in the future
i = 4
threshold = 0.00584
Now training 4 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 4 days prediction in the future
Now evaluating 4 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.43      0.43      0.43      1182
           0       0.33      0.39      0.35      1006
           1       0.50      0.44      0.47      1534

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.42      3722
weighted avg       0.43      0.42      0.43      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.41      0.44      0.42      1182
           0       0.34      0.51      0.41      1006
           1       0.51      0.32      0.39      1534

    accuracy                           0.41      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.43      0.41      0.41      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.37      0.39      0.38      1182
           0       0.34      0.40      0.36      1006
           1       0.46      0.39      0.43      1534

    accuracy                           0.39      3722
   macro avg       0.39      0.39      0.39      3722
weighted avg       0.40      0.39      0.39      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.37      0.41      0.39      1182
           0       0.34      0.60      0.43      1006
           1       0.48      0.19      0.28      1534

    accuracy                           0.37      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.41      0.37      0.35      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.52      0.52      0.52      1182
           0       0.41      0.45      0.43      1006
           1       0.61      0.57      0.59      1534

    accuracy                           0.52      3722
   macro avg       0.51      0.51      0.51      3722
weighted avg       0.53      0.52      0.52      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.40      0.22      0.28      1182
           0       0.37      0.43      0.40      1006
           1       0.45      0.56      0.50      1534

    accuracy                           0.42      3722
   macro avg       0.41      0.40      0.39      3722
weighted avg       0.41      0.42      0.40      3722

Now plotting 4 days prediction in the future
i = 5
threshold = 0.00675
Now training 5 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 5 days prediction in the future
Now evaluating 5 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.44      0.46      0.45      1145
           0       0.38      0.43      0.41      1056
           1       0.55      0.49      0.51      1521

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.46      3722
weighted avg       0.47      0.46      0.46      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.40      0.39      1145
           0       0.38      0.48      0.42      1056
           1       0.49      0.38      0.42      1521

    accuracy                           0.41      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.42      0.41      0.41      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.38      0.40      0.39      1145
           0       0.34      0.39      0.36      1056
           1       0.47      0.40      0.44      1521

    accuracy                           0.40      3722
   macro avg       0.40      0.40      0.40      3722
weighted avg       0.41      0.40      0.40      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.36      0.41      0.38      1145
           0       0.35      0.61      0.44      1056
           1       0.47      0.19      0.27      1521

    accuracy                           0.37      3722
   macro avg       0.39      0.40      0.36      3722
weighted avg       0.40      0.37      0.35      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.56      0.56      0.56      1145
           0       0.45      0.47      0.46      1056
           1       0.62      0.60      0.61      1521

    accuracy                           0.55      3722
   macro avg       0.54      0.54      0.54      3722
weighted avg       0.55      0.55      0.55      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.40      0.28      0.33      1145
           0       0.37      0.50      0.42      1056
           1       0.48      0.47      0.47      1521

    accuracy                           0.42      3722
   macro avg       0.41      0.42      0.41      3722
weighted avg       0.42      0.42      0.42      3722

Now plotting 5 days prediction in the future
i = 6
threshold = 0.00764
Now training 6 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 6 days prediction in the future
Now evaluating 6 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.43      0.43      0.43      1113
           0       0.39      0.45      0.42      1090
           1       0.53      0.47      0.49      1519

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.46      0.45      0.45      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.41      0.40      1113
           0       0.39      0.51      0.44      1090
           1       0.53      0.39      0.44      1519

    accuracy                           0.43      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.44      0.43      0.43      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.38      0.42      0.40      1113
           0       0.37      0.42      0.39      1090
           1       0.50      0.42      0.45      1519

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.42      3722
weighted avg       0.43      0.42      0.42      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.36      0.41      0.38      1113
           0       0.38      0.63      0.47      1090
           1       0.49      0.20      0.29      1519

    accuracy                           0.39      3722
   macro avg       0.41      0.41      0.38      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.55      0.58      0.56      1113
           0       0.50      0.53      0.51      1090
           1       0.65      0.60      0.63      1519

    accuracy                           0.57      3722
   macro avg       0.57      0.57      0.57      3722
weighted avg       0.58      0.57      0.57      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.39      0.31      0.35      1113
           0       0.39      0.56      0.46      1090
           1       0.47      0.40      0.43      1519

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.43      0.42      0.42      3722

Now plotting 6 days prediction in the future
i = 7
threshold = 0.00851
Now training 7 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 5}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 7 days prediction in the future
Now evaluating 7 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.42      0.46      0.44      1097
           0       0.36      0.40      0.38      1091
           1       0.54      0.46      0.50      1534

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.44      0.44      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.47      0.41      1097
           0       0.41      0.45      0.43      1091
           1       0.49      0.36      0.41      1534

    accuracy                           0.42      3722
   macro avg       0.42      0.43      0.42      3722
weighted avg       0.43      0.42      0.42      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.39      0.42      0.41      1097
           0       0.35      0.38      0.37      1091
           1       0.48      0.42      0.45      1534

    accuracy                           0.41      3722
   macro avg       0.41      0.41      0.41      3722
weighted avg       0.42      0.41      0.41      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.33      0.40      0.36      1097
           0       0.36      0.59      0.45      1091
           1       0.49      0.19      0.28      1534

    accuracy                           0.37      3722
   macro avg       0.39      0.39      0.36      3722
weighted avg       0.41      0.37      0.35      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.56      0.60      0.58      1097
           0       0.50      0.47      0.48      1091
           1       0.63      0.62      0.63      1534

    accuracy                           0.57      3722
   macro avg       0.56      0.56      0.56      3722
weighted avg       0.57      0.57      0.57      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.38      0.34      0.36      1097
           0       0.38      0.52      0.44      1091
           1       0.49      0.40      0.44      1534

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.42      0.42      0.41      3722

Now plotting 7 days prediction in the future
i = 8
threshold = 0.00936
Now training 8 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 8 days prediction in the future
Now evaluating 8 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.43      0.45      0.44      1065
           0       0.41      0.45      0.43      1135
           1       0.54      0.47      0.50      1522

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.46      3722
weighted avg       0.46      0.46      0.46      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.47      0.40      1065
           0       0.40      0.46      0.43      1135
           1       0.52      0.34      0.41      1522

    accuracy                           0.41      3722
   macro avg       0.43      0.42      0.41      3722
weighted avg       0.44      0.41      0.41      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.37      0.42      0.39      1065
           0       0.37      0.41      0.39      1135
           1       0.47      0.40      0.43      1522

    accuracy                           0.41      3722
   macro avg       0.41      0.41      0.41      3722
weighted avg       0.41      0.41      0.41      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.33      0.41      0.37      1065
           0       0.37      0.59      0.46      1135
           1       0.49      0.20      0.28      1522

    accuracy                           0.38      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.41      0.38      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.56      0.60      0.58      1065
           0       0.52      0.52      0.52      1135
           1       0.67      0.64      0.65      1522

    accuracy                           0.59      3722
   macro avg       0.58      0.59      0.59      3722
weighted avg       0.59      0.59      0.59      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.38      0.31      0.34      1065
           0       0.38      0.60      0.46      1135
           1       0.52      0.36      0.42      1522

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.43      0.42      0.41      3722

Now plotting 8 days prediction in the future
i = 9
threshold = 0.010190000000000001
Now training 9 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 9 days prediction in the future
Now evaluating 9 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.42      0.48      0.45      1036
           0       0.43      0.43      0.43      1173
           1       0.55      0.50      0.53      1513

    accuracy                           0.47      3722
   macro avg       0.47      0.47      0.47      3722
weighted avg       0.48      0.47      0.48      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.47      0.40      1036
           0       0.41      0.46      0.44      1173
           1       0.51      0.35      0.41      1513

    accuracy                           0.42      3722
   macro avg       0.43      0.43      0.42      3722
weighted avg       0.44      0.42      0.42      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.42      0.38      1036
           0       0.40      0.40      0.40      1173
           1       0.48      0.42      0.45      1513

    accuracy                           0.41      3722
   macro avg       0.41      0.41      0.41      3722
weighted avg       0.42      0.41      0.42      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.33      0.42      0.37      1036
           0       0.39      0.59      0.47      1173
           1       0.48      0.20      0.28      1513

    accuracy                           0.38      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.41      0.38      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.55      0.61      0.58      1036
           0       0.54      0.53      0.54      1173
           1       0.66      0.62      0.64      1513

    accuracy                           0.59      3722
   macro avg       0.58      0.59      0.59      3722
weighted avg       0.59      0.59      0.59      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.39      0.39      0.39      1036
           0       0.41      0.53      0.46      1173
           1       0.51      0.39      0.44      1513

    accuracy                           0.43      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.44      0.43      0.43      3722

Now plotting 9 days prediction in the future
i = 10
threshold = 0.011
Now training 10 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.1, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 10 days prediction in the future
Now evaluating 10 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.44      0.52      0.48      1014
           0       0.44      0.46      0.45      1195
           1       0.57      0.49      0.52      1513

    accuracy                           0.49      3722
   macro avg       0.49      0.49      0.49      3722
weighted avg       0.49      0.49      0.49      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.36      0.51      0.42      1014
           0       0.42      0.46      0.44      1195
           1       0.51      0.34      0.41      1513

    accuracy                           0.42      3722
   macro avg       0.43      0.44      0.42      3722
weighted avg       0.44      0.42      0.42      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.36      0.40      0.38      1014
           0       0.41      0.43      0.42      1195
           1       0.52      0.45      0.48      1513

    accuracy                           0.43      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.44      0.43      0.43      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.34      0.44      0.38      1014
           0       0.40      0.59      0.47      1195
           1       0.48      0.20      0.29      1513

    accuracy                           0.39      3722
   macro avg       0.41      0.41      0.38      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.59      0.64      0.61      1014
           0       0.57      0.54      0.56      1195
           1       0.69      0.68      0.69      1513

    accuracy                           0.63      3722
   macro avg       0.62      0.62      0.62      3722
weighted avg       0.63      0.63      0.62      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.38      0.41      0.40      1014
           0       0.42      0.54      0.47      1195
           1       0.51      0.36      0.42      1513

    accuracy                           0.43      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.45      0.43      0.43      3722

Now plotting 10 days prediction in the future
i = 11
threshold = 0.011789999999999998
Now training 11 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 3, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 11 days prediction in the future
Now evaluating 11 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.41      0.46      0.44      1005
           0       0.40      0.41      0.41      1200
           1       0.56      0.51      0.53      1517

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.46      3722
weighted avg       0.47      0.46      0.47      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.43      0.38      1005
           0       0.41      0.49      0.45      1200
           1       0.52      0.36      0.42      1517

    accuracy                           0.42      3722
   macro avg       0.43      0.43      0.42      3722
weighted avg       0.44      0.42      0.42      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.40      0.37      1005
           0       0.40      0.43      0.41      1200
           1       0.51      0.42      0.46      1517

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.41      3722
weighted avg       0.43      0.42      0.42      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.31      0.36      0.33      1005
           0       0.38      0.58      0.46      1200
           1       0.48      0.22      0.30      1517

    accuracy                           0.38      3722
   macro avg       0.39      0.39      0.37      3722
weighted avg       0.40      0.38      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.58      0.62      0.60      1005
           0       0.55      0.54      0.54      1200
           1       0.70      0.67      0.68      1517

    accuracy                           0.62      3722
   macro avg       0.61      0.61      0.61      3722
weighted avg       0.62      0.62      0.62      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.38      0.35      0.36      1005
           0       0.41      0.51      0.45      1200
           1       0.51      0.44      0.47      1517

    accuracy                           0.44      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.44      0.44      0.44      3722

Now plotting 11 days prediction in the future
i = 12
threshold = 0.01256
Now training 12 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 12 days prediction in the future
Now evaluating 12 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.43      0.49      0.46       979
           0       0.45      0.45      0.45      1222
           1       0.56      0.50      0.53      1521

    accuracy                           0.48      3722
   macro avg       0.48      0.48      0.48      3722
weighted avg       0.49      0.48      0.48      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.34      0.44      0.38       979
           0       0.42      0.48      0.45      1222
           1       0.52      0.37      0.43      1521

    accuracy                           0.42      3722
   macro avg       0.43      0.43      0.42      3722
weighted avg       0.44      0.42      0.43      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.37      0.43      0.40       979
           0       0.40      0.40      0.40      1222
           1       0.49      0.44      0.46      1521

    accuracy                           0.42      3722
   macro avg       0.42      0.42      0.42      3722
weighted avg       0.43      0.42      0.43      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.31      0.39      0.35       979
           0       0.40      0.60      0.48      1222
           1       0.51      0.22      0.31      1521

    accuracy                           0.39      3722
   macro avg       0.41      0.40      0.38      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.59      0.62      0.60       979
           0       0.58      0.58      0.58      1222
           1       0.71      0.68      0.69      1521

    accuracy                           0.63      3722
   macro avg       0.63      0.63      0.63      3722
weighted avg       0.63      0.63      0.63      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.38      0.41      0.39       979
           0       0.41      0.60      0.49      1222
           1       0.55      0.33      0.41      1521

    accuracy                           0.44      3722
   macro avg       0.45      0.45      0.43      3722
weighted avg       0.46      0.44      0.43      3722

Now plotting 12 days prediction in the future
i = 13
threshold = 0.01331
Now training 13 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 3, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 1, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 13 days prediction in the future
Now evaluating 13 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.42      0.48      0.45       967
           0       0.47      0.49      0.48      1227
           1       0.57      0.51      0.54      1528

    accuracy                           0.50      3722
   macro avg       0.49      0.49      0.49      3722
weighted avg       0.50      0.50      0.50      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.36      0.49      0.42       967
           0       0.47      0.49      0.48      1227
           1       0.53      0.39      0.45      1528

    accuracy                           0.45      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.46      0.45      0.45      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.36      0.43      0.39       967
           0       0.44      0.45      0.44      1227
           1       0.52      0.44      0.48      1528

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.32      0.40      0.35       967
           0       0.41      0.60      0.49      1227
           1       0.51      0.24      0.33      1528

    accuracy                           0.40      3722
   macro avg       0.41      0.41      0.39      3722
weighted avg       0.43      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.59      0.64      0.61       967
           0       0.62      0.58      0.60      1227
           1       0.71      0.70      0.71      1528

    accuracy                           0.65      3722
   macro avg       0.64      0.64      0.64      3722
weighted avg       0.65      0.65      0.65      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.41      0.38       967
           0       0.45      0.34      0.39      1227
           1       0.47      0.51      0.49      1528

    accuracy                           0.43      3722
   macro avg       0.42      0.42      0.42      3722
weighted avg       0.43      0.43      0.43      3722

Now plotting 13 days prediction in the future
i = 14
threshold = 0.01404
Now training 14 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 14 days prediction in the future
Now evaluating 14 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.48      0.57      0.52       941
           0       0.50      0.49      0.50      1253
           1       0.64      0.58      0.61      1528

    accuracy                           0.55      3722
   macro avg       0.54      0.55      0.54      3722
weighted avg       0.56      0.55      0.55      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.36      0.48      0.42       941
           0       0.46      0.50      0.48      1253
           1       0.56      0.40      0.47      1528

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.47      0.46      0.46      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.44      0.39       941
           0       0.43      0.43      0.43      1253
           1       0.52      0.44      0.48      1528

    accuracy                           0.44      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.45      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.32      0.40      0.36       941
           0       0.41      0.62      0.50      1253
           1       0.54      0.25      0.34      1528

    accuracy                           0.41      3722
   macro avg       0.42      0.42      0.40      3722
weighted avg       0.44      0.41      0.40      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.60      0.68      0.64       941
           0       0.63      0.60      0.61      1253
           1       0.74      0.71      0.73      1528

    accuracy                           0.66      3722
   macro avg       0.66      0.66      0.66      3722
weighted avg       0.67      0.66      0.66      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.36      0.42      0.39       941
           0       0.45      0.55      0.49      1253
           1       0.53      0.37      0.43      1528

    accuracy                           0.44      3722
   macro avg       0.44      0.45      0.44      3722
weighted avg       0.46      0.44      0.44      3722

Now plotting 14 days prediction in the future
i = 15
threshold = 0.014750000000000001
Now training 15 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.1, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 15 days prediction in the future
Now evaluating 15 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.42      0.49      0.45       930
           0       0.47      0.47      0.47      1276
           1       0.58      0.52      0.55      1516

    accuracy                           0.50      3722
   macro avg       0.49      0.50      0.49      3722
weighted avg       0.50      0.50      0.50      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.36      0.48      0.41       930
           0       0.43      0.52      0.47      1276
           1       0.53      0.33      0.41      1516

    accuracy                           0.43      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.45      0.43      0.43      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.46      0.40       930
           0       0.44      0.43      0.43      1276
           1       0.51      0.42      0.46      1516

    accuracy                           0.43      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.44      0.43      0.43      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.31      0.41      0.36       930
           0       0.42      0.60      0.49      1276
           1       0.51      0.23      0.32      1516

    accuracy                           0.40      3722
   macro avg       0.42      0.41      0.39      3722
weighted avg       0.43      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.61      0.68      0.64       930
           0       0.63      0.60      0.61      1276
           1       0.72      0.70      0.71      1516

    accuracy                           0.66      3722
   macro avg       0.65      0.66      0.66      3722
weighted avg       0.66      0.66      0.66      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.45      0.39       930
           0       0.47      0.41      0.44      1276
           1       0.50      0.46      0.48      1516

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.44      0.44      3722

Now plotting 15 days prediction in the future
i = 16
threshold = 0.015440000000000002
Now training 16 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.1, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 16 days prediction in the future
Now evaluating 16 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.44      0.49      0.46       925
           0       0.48      0.47      0.48      1278
           1       0.60      0.57      0.58      1519

    accuracy                           0.52      3722
   macro avg       0.51      0.51      0.51      3722
weighted avg       0.52      0.52      0.52      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.36      0.44      0.40       925
           0       0.45      0.52      0.48      1278
           1       0.56      0.41      0.47      1519

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.47      0.46      0.46      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.40      0.37       925
           0       0.43      0.45      0.44      1278
           1       0.51      0.44      0.47      1519

    accuracy                           0.43      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.44      0.43      0.43      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.30      0.39      0.34       925
           0       0.42      0.58      0.49      1278
           1       0.49      0.24      0.32      1519

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.38      3722
weighted avg       0.42      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.61      0.65      0.63       925
           0       0.63      0.60      0.61      1278
           1       0.74      0.73      0.73      1519

    accuracy                           0.66      3722
   macro avg       0.66      0.66      0.66      3722
weighted avg       0.67      0.66      0.67      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.33      0.34       925
           0       0.43      0.62      0.51      1278
           1       0.55      0.36      0.44      1519

    accuracy                           0.45      3722
   macro avg       0.45      0.44      0.43      3722
weighted avg       0.46      0.45      0.44      3722

Now plotting 16 days prediction in the future
i = 17
threshold = 0.016110000000000003
Now training 17 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 17 days prediction in the future
Now evaluating 17 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.45      0.52      0.48       923
           0       0.52      0.53      0.52      1278
           1       0.63      0.56      0.59      1521

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.55      0.54      0.54      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.45      0.39       923
           0       0.45      0.49      0.47      1278
           1       0.56      0.43      0.48      1521

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.47      0.45      0.46      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.43      0.38       923
           0       0.43      0.42      0.42      1278
           1       0.53      0.45      0.49      1521

    accuracy                           0.44      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.45      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.36      0.33       923
           0       0.41      0.59      0.48      1278
           1       0.52      0.25      0.34      1521

    accuracy                           0.40      3722
   macro avg       0.41      0.40      0.38      3722
weighted avg       0.43      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.61      0.70      0.65       923
           0       0.63      0.60      0.61      1278
           1       0.74      0.71      0.72      1521

    accuracy                           0.67      3722
   macro avg       0.66      0.67      0.66      3722
weighted avg       0.67      0.67      0.67      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.36      0.36       923
           0       0.44      0.52      0.48      1278
           1       0.52      0.44      0.48      1521

    accuracy                           0.45      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.45      0.45      3722

Now plotting 17 days prediction in the future
i = 18
threshold = 0.016760000000000004
Now training 18 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 18 days prediction in the future
Now evaluating 18 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.45      0.50      0.47       909
           0       0.49      0.50      0.50      1281
           1       0.62      0.55      0.58      1532

    accuracy                           0.52      3722
   macro avg       0.52      0.52      0.52      3722
weighted avg       0.53      0.52      0.53      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.51      0.41       909
           0       0.48      0.46      0.47      1281
           1       0.55      0.41      0.47      1532

    accuracy                           0.45      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.48      0.45      0.46      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.44      0.37       909
           0       0.46      0.46      0.46      1281
           1       0.53      0.42      0.47      1532

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.45      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.30      0.38      0.33       909
           0       0.41      0.59      0.49      1281
           1       0.52      0.24      0.33      1532

    accuracy                           0.40      3722
   macro avg       0.41      0.40      0.38      3722
weighted avg       0.43      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.63      0.70      0.66       909
           0       0.64      0.65      0.64      1281
           1       0.76      0.71      0.73      1532

    accuracy                           0.69      3722
   macro avg       0.68      0.69      0.68      3722
weighted avg       0.69      0.69      0.69      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.39      0.30      0.34       909
           0       0.43      0.60      0.50      1281
           1       0.52      0.43      0.47      1532

    accuracy                           0.46      3722
   macro avg       0.45      0.44      0.44      3722
weighted avg       0.46      0.46      0.45      3722

Now plotting 18 days prediction in the future
i = 19
threshold = 0.017389999999999996
Now training 19 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 19 days prediction in the future
Now evaluating 19 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.62      0.57       909
           0       0.58      0.58      0.58      1287
           1       0.70      0.63      0.66      1526

    accuracy                           0.61      3722
   macro avg       0.60      0.61      0.60      3722
weighted avg       0.62      0.61      0.61      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.48      0.43       909
           0       0.43      0.51      0.47      1287
           1       0.55      0.40      0.46      1526

    accuracy                           0.45      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.47      0.45      0.46      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.43      0.38       909
           0       0.42      0.41      0.41      1287
           1       0.51      0.44      0.47      1526

    accuracy                           0.43      3722
   macro avg       0.42      0.43      0.42      3722
weighted avg       0.44      0.43      0.43      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.38      0.33       909
           0       0.42      0.58      0.49      1287
           1       0.49      0.25      0.33      1526

    accuracy                           0.40      3722
   macro avg       0.40      0.40      0.38      3722
weighted avg       0.42      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.64      0.73      0.68       909
           0       0.67      0.62      0.64      1287
           1       0.76      0.74      0.75      1526

    accuracy                           0.70      3722
   macro avg       0.69      0.70      0.69      3722
weighted avg       0.70      0.70      0.70      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.36      0.34      0.35       909
           0       0.44      0.56      0.49      1287
           1       0.52      0.42      0.47      1526

    accuracy                           0.45      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.45      0.45      3722

Now plotting 19 days prediction in the future
i = 20
threshold = 0.018
Now training 20 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 1, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 20 days prediction in the future
Now evaluating 20 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.52      0.62      0.57       913
           0       0.57      0.57      0.57      1267
           1       0.68      0.60      0.63      1542

    accuracy                           0.59      3722
   macro avg       0.59      0.60      0.59      3722
weighted avg       0.60      0.59      0.60      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.50      0.43       913
           0       0.46      0.47      0.46      1267
           1       0.57      0.46      0.51      1542

    accuracy                           0.47      3722
   macro avg       0.47      0.47      0.47      3722
weighted avg       0.49      0.47      0.47      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.37      0.47      0.42       913
           0       0.44      0.48      0.46      1267
           1       0.54      0.42      0.47      1542

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.46      0.45      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.31      0.40      0.35       913
           0       0.40      0.57      0.47      1267
           1       0.48      0.23      0.31      1542

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.38      3722
weighted avg       0.41      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.63      0.74      0.68       913
           0       0.65      0.63      0.64      1267
           1       0.78      0.72      0.75      1542

    accuracy                           0.70      3722
   macro avg       0.69      0.70      0.69      3722
weighted avg       0.70      0.70      0.70      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.49      0.40       913
           0       0.44      0.47      0.45      1267
           1       0.53      0.36      0.43      1542

    accuracy                           0.43      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.45      0.43      0.43      3722

Now plotting 20 days prediction in the future
i = 21
threshold = 0.01859
Now training 21 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 3, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 21 days prediction in the future
Now evaluating 21 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.44      0.52      0.48       891
           0       0.52      0.52      0.52      1295
           1       0.64      0.57      0.60      1536

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.55      0.54      0.54      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.48      0.41       891
           0       0.44      0.49      0.46      1295
           1       0.60      0.41      0.49      1536

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.48      0.46      0.46      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.45      0.39       891
           0       0.43      0.44      0.44      1295
           1       0.55      0.44      0.49      1536

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.46      0.44      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.39      0.34       891
           0       0.42      0.58      0.49      1295
           1       0.52      0.26      0.35      1536

    accuracy                           0.40      3722
   macro avg       0.41      0.41      0.39      3722
weighted avg       0.43      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.62      0.71      0.66       891
           0       0.66      0.61      0.64      1295
           1       0.76      0.74      0.75      1536

    accuracy                           0.69      3722
   macro avg       0.68      0.69      0.68      3722
weighted avg       0.69      0.69      0.69      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.41      0.37       891
           0       0.44      0.50      0.46      1295
           1       0.53      0.41      0.46      1536

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.45      0.44      0.44      3722

Now plotting 21 days prediction in the future
i = 22
threshold = 0.01916
Now training 22 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 22 days prediction in the future
Now evaluating 22 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.61      0.57       884
           0       0.59      0.58      0.58      1290
           1       0.71      0.66      0.68      1548

    accuracy                           0.62      3722
   macro avg       0.61      0.61      0.61      3722
weighted avg       0.62      0.62      0.62      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.49      0.43       884
           0       0.49      0.45      0.47      1290
           1       0.59      0.52      0.56      1548

    accuracy                           0.49      3722
   macro avg       0.49      0.49      0.48      3722
weighted avg       0.51      0.49      0.49      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.42      0.38       884
           0       0.45      0.46      0.46      1290
           1       0.56      0.48      0.52      1548

    accuracy                           0.46      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.47      0.46      0.46      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.39      0.33       884
           0       0.41      0.61      0.49      1290
           1       0.54      0.21      0.30      1548

    accuracy                           0.39      3722
   macro avg       0.41      0.40      0.38      3722
weighted avg       0.44      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.65      0.72      0.68       884
           0       0.66      0.65      0.65      1290
           1       0.79      0.74      0.77      1548

    accuracy                           0.71      3722
   macro avg       0.70      0.71      0.70      3722
weighted avg       0.71      0.71      0.71      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.46      0.39       884
           0       0.45      0.49      0.47      1290
           1       0.56      0.40      0.46      1548

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.47      0.45      0.45      3722

Now plotting 22 days prediction in the future
i = 23
threshold = 0.019710000000000002
Now training 23 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 23 days prediction in the future
Now evaluating 23 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.62      0.57       880
           0       0.57      0.60      0.59      1294
           1       0.75      0.64      0.69      1548

    accuracy                           0.62      3722
   macro avg       0.62      0.62      0.62      3722
weighted avg       0.63      0.62      0.63      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.40      0.53      0.46       880
           0       0.49      0.51      0.50      1294
           1       0.61      0.48      0.53      1548

    accuracy                           0.50      3722
   macro avg       0.50      0.51      0.50      3722
weighted avg       0.52      0.50      0.51      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.42      0.37       880
           0       0.45      0.45      0.45      1294
           1       0.53      0.45      0.49      1548

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.44      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.30      0.39      0.34       880
           0       0.42      0.59      0.49      1294
           1       0.50      0.24      0.32      1548

    accuracy                           0.40      3722
   macro avg       0.41      0.41      0.38      3722
weighted avg       0.42      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.64      0.72      0.68       880
           0       0.69      0.67      0.68      1294
           1       0.80      0.76      0.78      1548

    accuracy                           0.72      3722
   macro avg       0.71      0.72      0.71      3722
weighted avg       0.72      0.72      0.72      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.38      0.36       880
           0       0.44      0.47      0.46      1294
           1       0.51      0.44      0.47      1548

    accuracy                           0.44      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.45      0.44      0.44      3722

Now plotting 23 days prediction in the future
i = 24
threshold = 0.02024
Now training 24 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 24 days prediction in the future
Now evaluating 24 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.52      0.61      0.56       875
           0       0.59      0.58      0.59      1300
           1       0.71      0.64      0.67      1547

    accuracy                           0.61      3722
   macro avg       0.61      0.61      0.61      3722
weighted avg       0.62      0.61      0.62      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.53      0.45       875
           0       0.49      0.52      0.50      1300
           1       0.62      0.46      0.53      1547

    accuracy                           0.50      3722
   macro avg       0.50      0.50      0.49      3722
weighted avg       0.52      0.50      0.50      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.41      0.37       875
           0       0.44      0.45      0.44      1300
           1       0.54      0.45      0.49      1547

    accuracy                           0.44      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.45      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.38      0.33       875
           0       0.41      0.58      0.48      1300
           1       0.50      0.24      0.32      1547

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.38      3722
weighted avg       0.42      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.65      0.73      0.69       875
           0       0.70      0.67      0.68      1300
           1       0.79      0.76      0.77      1547

    accuracy                           0.72      3722
   macro avg       0.71      0.72      0.71      3722
weighted avg       0.72      0.72      0.72      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.37      0.43      0.40       875
           0       0.45      0.57      0.50      1300
           1       0.55      0.37      0.44      1547

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.47      0.46      0.45      3722

Now plotting 24 days prediction in the future
i = 25
threshold = 0.020750000000000005
Now training 25 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 25 days prediction in the future
Now evaluating 25 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.44      0.53      0.48       856
           0       0.53      0.52      0.52      1311
           1       0.64      0.57      0.60      1555

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.54      3722
weighted avg       0.55      0.54      0.55      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.34      0.53      0.42       856
           0       0.48      0.44      0.46      1311
           1       0.60      0.46      0.52      1555

    accuracy                           0.47      3722
   macro avg       0.47      0.48      0.46      3722
weighted avg       0.50      0.47      0.47      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.42      0.36       856
           0       0.45      0.45      0.45      1311
           1       0.53      0.44      0.48      1555

    accuracy                           0.44      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.46      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.40      0.33       856
           0       0.41      0.58      0.48      1311
           1       0.51      0.22      0.31      1555

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.64      0.75      0.69       856
           0       0.70      0.68      0.69      1311
           1       0.79      0.73      0.76      1555

    accuracy                           0.72      3722
   macro avg       0.71      0.72      0.71      3722
weighted avg       0.72      0.72      0.72      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.36      0.42      0.39       856
           0       0.45      0.51      0.48      1311
           1       0.53      0.42      0.47      1555

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.46      0.45      0.45      3722

Now plotting 25 days prediction in the future
i = 26
threshold = 0.021240000000000002
Now training 26 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 26 days prediction in the future
Now evaluating 26 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.52      0.62      0.57       847
           0       0.60      0.63      0.62      1317
           1       0.74      0.64      0.69      1558

    accuracy                           0.63      3722
   macro avg       0.62      0.63      0.62      3722
weighted avg       0.64      0.63      0.63      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.54      0.44       847
           0       0.47      0.50      0.48      1317
           1       0.61      0.42      0.49      1558

    accuracy                           0.47      3722
   macro avg       0.48      0.48      0.47      3722
weighted avg       0.50      0.47      0.48      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.30      0.41      0.35       847
           0       0.46      0.47      0.47      1317
           1       0.53      0.42      0.47      1558

    accuracy                           0.44      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.46      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.38      0.32       847
           0       0.42      0.59      0.49      1317
           1       0.50      0.23      0.32      1558

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.59      0.70      0.64       847
           0       0.69      0.67      0.68      1317
           1       0.81      0.75      0.78      1558

    accuracy                           0.71      3722
   macro avg       0.70      0.71      0.70      3722
weighted avg       0.72      0.71      0.71      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.47      0.39       847
           0       0.45      0.55      0.50      1317
           1       0.58      0.35      0.44      1558

    accuracy                           0.45      3722
   macro avg       0.46      0.46      0.44      3722
weighted avg       0.48      0.45      0.45      3722

Now plotting 26 days prediction in the future
i = 27
threshold = 0.021709999999999997
Now training 27 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 27 days prediction in the future
Now evaluating 27 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.52      0.61      0.57       841
           0       0.62      0.63      0.62      1327
           1       0.74      0.66      0.70      1554

    accuracy                           0.64      3722
   macro avg       0.63      0.63      0.63      3722
weighted avg       0.65      0.64      0.64      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.54      0.44       841
           0       0.50      0.52      0.51      1327
           1       0.61      0.44      0.51      1554

    accuracy                           0.49      3722
   macro avg       0.50      0.50      0.49      3722
weighted avg       0.52      0.49      0.50      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.31      0.40      0.35       841
           0       0.45      0.45      0.45      1327
           1       0.53      0.46      0.49      1554

    accuracy                           0.44      3722
   macro avg       0.43      0.43      0.43      3722
weighted avg       0.45      0.44      0.44      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.39      0.33       841
           0       0.42      0.61      0.50      1327
           1       0.49      0.20      0.28      1554

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.68      0.77      0.72       841
           0       0.73      0.71      0.72      1327
           1       0.82      0.77      0.79      1554

    accuracy                           0.75      3722
   macro avg       0.74      0.75      0.75      3722
weighted avg       0.75      0.75      0.75      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.37      0.40      0.38       841
           0       0.45      0.59      0.51      1327
           1       0.55      0.38      0.45      1554

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.47      0.46      0.46      3722

Now plotting 27 days prediction in the future
i = 28
threshold = 0.02216
Now training 28 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 28 days prediction in the future
Now evaluating 28 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.64      0.58       839
           0       0.60      0.61      0.61      1327
           1       0.74      0.65      0.69      1556

    accuracy                           0.63      3722
   macro avg       0.62      0.63      0.63      3722
weighted avg       0.64      0.63      0.64      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.52      0.44       839
           0       0.51      0.45      0.48      1327
           1       0.60      0.54      0.57      1556

    accuracy                           0.50      3722
   macro avg       0.50      0.50      0.50      3722
weighted avg       0.52      0.50      0.51      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.46      0.38       839
           0       0.46      0.46      0.46      1327
           1       0.56      0.43      0.49      1556

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.47      0.45      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.42      0.34       839
           0       0.42      0.59      0.49      1327
           1       0.49      0.20      0.28      1556

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.63      0.73      0.68       839
           0       0.70      0.69      0.69      1327
           1       0.81      0.75      0.78      1556

    accuracy                           0.72      3722
   macro avg       0.71      0.72      0.72      3722
weighted avg       0.73      0.72      0.72      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.46      0.40       839
           0       0.46      0.45      0.45      1327
           1       0.50      0.42      0.46      1556

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.45      0.44      0.44      3722

Now plotting 28 days prediction in the future
i = 29
threshold = 0.02259
Now training 29 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 29 days prediction in the future
Now evaluating 29 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.64      0.58       830
           0       0.60      0.60      0.60      1326
           1       0.73      0.66      0.69      1566

    accuracy                           0.63      3722
   macro avg       0.62      0.63      0.62      3722
weighted avg       0.64      0.63      0.63      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.56      0.44       830
           0       0.50      0.46      0.48      1326
           1       0.61      0.48      0.53      1566

    accuracy                           0.49      3722
   macro avg       0.49      0.50      0.48      3722
weighted avg       0.51      0.49      0.49      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.43      0.37       830
           0       0.45      0.42      0.44      1326
           1       0.53      0.46      0.49      1566

    accuracy                           0.44      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.46      0.44      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.43      0.34       830
           0       0.42      0.58      0.49      1326
           1       0.50      0.19      0.28      1566

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.61      0.73      0.67       830
           0       0.70      0.65      0.68      1326
           1       0.79      0.76      0.77      1566

    accuracy                           0.71      3722
   macro avg       0.70      0.71      0.71      3722
weighted avg       0.72      0.71      0.72      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.36      0.35       830
           0       0.45      0.53      0.49      1326
           1       0.53      0.44      0.48      1566

    accuracy                           0.45      3722
   macro avg       0.44      0.44      0.44      3722
weighted avg       0.46      0.45      0.45      3722

Now plotting 29 days prediction in the future
i = 30
threshold = 0.023
Now training 30 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 30 days prediction in the future
Now evaluating 30 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.52      0.60      0.56       829
           0       0.61      0.61      0.61      1324
           1       0.72      0.67      0.69      1569

    accuracy                           0.63      3722
   macro avg       0.62      0.63      0.62      3722
weighted avg       0.64      0.63      0.63      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.54      0.43       829
           0       0.50      0.49      0.49      1324
           1       0.61      0.46      0.52      1569

    accuracy                           0.49      3722
   macro avg       0.49      0.49      0.48      3722
weighted avg       0.51      0.49      0.49      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.48      0.40       829
           0       0.48      0.46      0.47      1324
           1       0.54      0.45      0.49      1569

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.48      0.46      0.46      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.27      0.42      0.33       829
           0       0.42      0.56      0.48      1324
           1       0.49      0.21      0.29      1569

    accuracy                           0.38      3722
   macro avg       0.39      0.40      0.37      3722
weighted avg       0.42      0.38      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.66      0.74      0.70       829
           0       0.73      0.68      0.70      1324
           1       0.79      0.78      0.79      1569

    accuracy                           0.74      3722
   macro avg       0.73      0.74      0.73      3722
weighted avg       0.74      0.74      0.74      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.33      0.49      0.39       829
           0       0.47      0.38      0.42      1324
           1       0.52      0.46      0.49      1569

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.46      0.44      0.44      3722

Now plotting 30 days prediction in the future
i = 31
threshold = 0.02339
Now training 31 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 1, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 31 days prediction in the future
Now evaluating 31 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.51      0.60      0.55       823
           0       0.60      0.60      0.60      1334
           1       0.70      0.64      0.67      1565

    accuracy                           0.62      3722
   macro avg       0.61      0.62      0.61      3722
weighted avg       0.63      0.62      0.62      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.60      0.45       823
           0       0.50      0.46      0.48      1334
           1       0.61      0.43      0.50      1565

    accuracy                           0.48      3722
   macro avg       0.49      0.50      0.47      3722
weighted avg       0.51      0.48      0.48      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.47      0.38       823
           0       0.48      0.46      0.47      1334
           1       0.56      0.43      0.49      1565

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.47      0.45      0.46      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.43      0.34       823
           0       0.43      0.57      0.49      1334
           1       0.50      0.21      0.30      1565

    accuracy                           0.39      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.64      0.76      0.70       823
           0       0.73      0.68      0.70      1334
           1       0.80      0.76      0.78      1565

    accuracy                           0.73      3722
   macro avg       0.72      0.74      0.73      3722
weighted avg       0.74      0.73      0.73      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.44      0.38       823
           0       0.46      0.53      0.49      1334
           1       0.55      0.40      0.46      1565

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.47      0.45      0.45      3722

Now plotting 31 days prediction in the future
i = 32
threshold = 0.023760000000000003
Now training 32 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 3, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 1, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 32 days prediction in the future
Now evaluating 32 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.50      0.60      0.54       819
           0       0.60      0.59      0.60      1339
           1       0.71      0.64      0.67      1564

    accuracy                           0.62      3722
   macro avg       0.60      0.61      0.61      3722
weighted avg       0.62      0.62      0.62      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.57      0.45       819
           0       0.51      0.45      0.48      1339
           1       0.63      0.51      0.56      1564

    accuracy                           0.50      3722
   macro avg       0.50      0.51      0.50      3722
weighted avg       0.53      0.50      0.51      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.30      0.42      0.35       819
           0       0.47      0.45      0.46      1339
           1       0.54      0.45      0.49      1564

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.43      3722
weighted avg       0.46      0.44      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.46      0.34       819
           0       0.43      0.59      0.50      1339
           1       0.50      0.17      0.25      1564

    accuracy                           0.38      3722
   macro avg       0.40      0.40      0.36      3722
weighted avg       0.43      0.38      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.64      0.75      0.69       819
           0       0.72      0.67      0.70      1339
           1       0.79      0.77      0.78      1564

    accuracy                           0.73      3722
   macro avg       0.72      0.73      0.72      3722
weighted avg       0.73      0.73      0.73      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.32      0.48      0.39       819
           0       0.49      0.38      0.43      1339
           1       0.53      0.49      0.51      1564

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.47      0.45      0.45      3722

Now plotting 32 days prediction in the future
i = 33
threshold = 0.02411
Now training 33 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.1, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 33 days prediction in the future
Now evaluating 33 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.55      0.64      0.59       816
           0       0.63      0.61      0.62      1339
           1       0.73      0.69      0.71      1567

    accuracy                           0.65      3722
   macro avg       0.64      0.65      0.64      3722
weighted avg       0.65      0.65      0.65      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.35      0.52      0.42       816
           0       0.48      0.48      0.48      1339
           1       0.63      0.48      0.54      1567

    accuracy                           0.49      3722
   macro avg       0.49      0.49      0.48      3722
weighted avg       0.52      0.49      0.49      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.42      0.36       816
           0       0.49      0.48      0.48      1339
           1       0.55      0.47      0.51      1567

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.27      0.46      0.34       816
           0       0.43      0.57      0.49      1339
           1       0.50      0.18      0.27      1567

    accuracy                           0.38      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.42      0.38      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.64      0.74      0.68       816
           0       0.74      0.68      0.71      1339
           1       0.80      0.79      0.79      1567

    accuracy                           0.74      3722
   macro avg       0.73      0.74      0.73      3722
weighted avg       0.74      0.74      0.74      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.32      0.49      0.38       816
           0       0.49      0.42      0.45      1339
           1       0.54      0.46      0.50      1567

    accuracy                           0.45      3722
   macro avg       0.45      0.45      0.44      3722
weighted avg       0.47      0.45      0.46      3722

Now plotting 33 days prediction in the future
i = 34
threshold = 0.024440000000000003
Now training 34 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 34 days prediction in the future
Now evaluating 34 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.52      0.62      0.57       815
           0       0.60      0.61      0.61      1336
           1       0.73      0.64      0.68      1571

    accuracy                           0.63      3722
   macro avg       0.62      0.63      0.62      3722
weighted avg       0.64      0.63      0.63      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.56      0.45       815
           0       0.51      0.53      0.52      1336
           1       0.66      0.49      0.57      1571

    accuracy                           0.52      3722
   macro avg       0.52      0.52      0.51      3722
weighted avg       0.55      0.52      0.52      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.45      0.38       815
           0       0.49      0.48      0.48      1336
           1       0.55      0.44      0.48      1571

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.46      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.45      0.35       815
           0       0.44      0.58      0.50      1336
           1       0.50      0.20      0.28      1571

    accuracy                           0.39      3722
   macro avg       0.41      0.41      0.38      3722
weighted avg       0.43      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.69      0.77      0.72       815
           0       0.75      0.72      0.73      1336
           1       0.82      0.80      0.81      1571

    accuracy                           0.76      3722
   macro avg       0.75      0.76      0.76      3722
weighted avg       0.76      0.76      0.76      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.47      0.40       815
           0       0.49      0.39      0.44      1336
           1       0.54      0.53      0.53      1571

    accuracy                           0.47      3722
   macro avg       0.46      0.47      0.46      3722
weighted avg       0.48      0.47      0.47      3722

Now plotting 34 days prediction in the future
i = 35
threshold = 0.02475
Now training 35 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 35 days prediction in the future
Now evaluating 35 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.56      0.67      0.61       816
           0       0.64      0.64      0.64      1320
           1       0.75      0.68      0.72      1586

    accuracy                           0.66      3722
   macro avg       0.65      0.66      0.65      3722
weighted avg       0.67      0.66      0.66      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.41      0.54      0.46       816
           0       0.50      0.47      0.48      1320
           1       0.62      0.55      0.58      1586

    accuracy                           0.52      3722
   macro avg       0.51      0.52      0.51      3722
weighted avg       0.53      0.52      0.52      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.43      0.37       816
           0       0.48      0.47      0.47      1320
           1       0.55      0.47      0.51      1586

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.48      0.36       816
           0       0.43      0.58      0.49      1320
           1       0.51      0.20      0.28      1586

    accuracy                           0.39      3722
   macro avg       0.41      0.42      0.38      3722
weighted avg       0.44      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.67      0.78      0.72       816
           0       0.75      0.69      0.72      1320
           1       0.82      0.80      0.81      1586

    accuracy                           0.76      3722
   macro avg       0.75      0.76      0.75      3722
weighted avg       0.76      0.76      0.76      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.36      0.46      0.40       816
           0       0.52      0.37      0.43      1320
           1       0.52      0.55      0.53      1586

    accuracy                           0.47      3722
   macro avg       0.46      0.46      0.46      3722
weighted avg       0.48      0.47      0.47      3722

Now plotting 35 days prediction in the future
i = 36
threshold = 0.025040000000000007
Now training 36 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 9, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 36 days prediction in the future
Now evaluating 36 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.61      0.57       808
           0       0.62      0.62      0.62      1324
           1       0.72      0.66      0.69      1590

    accuracy                           0.64      3722
   macro avg       0.62      0.63      0.63      3722
weighted avg       0.64      0.64      0.64      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.59      0.46       808
           0       0.51      0.48      0.50      1324
           1       0.64      0.49      0.56      1590

    accuracy                           0.51      3722
   macro avg       0.51      0.52      0.51      3722
weighted avg       0.54      0.51      0.52      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.49      0.39       808
           0       0.49      0.49      0.49      1324
           1       0.56      0.42      0.48      1590

    accuracy                           0.46      3722
   macro avg       0.46      0.46      0.45      3722
weighted avg       0.48      0.46      0.46      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.50      0.37       808
           0       0.43      0.59      0.50      1324
           1       0.50      0.16      0.25      1590

    accuracy                           0.39      3722
   macro avg       0.41      0.42      0.37      3722
weighted avg       0.43      0.39      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.68      0.76      0.72       808
           0       0.75      0.73      0.74      1324
           1       0.82      0.78      0.80      1590

    accuracy                           0.76      3722
   macro avg       0.75      0.76      0.75      3722
weighted avg       0.76      0.76      0.76      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.37      0.42      0.39       808
           0       0.48      0.43      0.45      1324
           1       0.51      0.52      0.52      1590

    accuracy                           0.47      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.47      0.47      0.47      3722

Now plotting 36 days prediction in the future
i = 37
threshold = 0.02531
Now training 37 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 5}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 37 days prediction in the future
Now evaluating 37 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.54      0.65      0.59       805
           0       0.62      0.63      0.63      1316
           1       0.74      0.65      0.69      1601

    accuracy                           0.64      3722
   macro avg       0.63      0.64      0.64      3722
weighted avg       0.65      0.64      0.65      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.50      0.43       805
           0       0.53      0.53      0.53      1316
           1       0.64      0.54      0.58      1601

    accuracy                           0.52      3722
   macro avg       0.51      0.52      0.51      3722
weighted avg       0.54      0.52      0.53      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.43      0.37       805
           0       0.48      0.47      0.47      1316
           1       0.55      0.48      0.51      1601

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.49      0.36       805
           0       0.44      0.60      0.51      1316
           1       0.53      0.19      0.28      1601

    accuracy                           0.40      3722
   macro avg       0.42      0.43      0.38      3722
weighted avg       0.45      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.68      0.78      0.73       805
           0       0.76      0.75      0.76      1316
           1       0.85      0.80      0.82      1601

    accuracy                           0.78      3722
   macro avg       0.76      0.78      0.77      3722
weighted avg       0.78      0.78      0.78      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.39      0.43      0.41       805
           0       0.48      0.56      0.52      1316
           1       0.58      0.47      0.52      1601

    accuracy                           0.49      3722
   macro avg       0.48      0.49      0.48      3722
weighted avg       0.50      0.49      0.50      3722

Now plotting 37 days prediction in the future
i = 38
threshold = 0.02556
Now training 38 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 38 days prediction in the future
Now evaluating 38 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.63      0.57       810
           0       0.64      0.68      0.66      1312
           1       0.77      0.66      0.71      1600

    accuracy                           0.66      3722
   macro avg       0.65      0.65      0.65      3722
weighted avg       0.67      0.66      0.66      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.60      0.46       810
           0       0.52      0.46      0.49      1312
           1       0.64      0.50      0.56      1600

    accuracy                           0.51      3722
   macro avg       0.51      0.52      0.50      3722
weighted avg       0.54      0.51      0.51      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.32      0.40      0.35       810
           0       0.48      0.49      0.48      1312
           1       0.56      0.48      0.52      1600

    accuracy                           0.46      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.48      0.46      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.49      0.36       810
           0       0.44      0.59      0.50      1312
           1       0.52      0.17      0.26      1600

    accuracy                           0.39      3722
   macro avg       0.41      0.42      0.38      3722
weighted avg       0.44      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.66      0.78      0.71       810
           0       0.75      0.72      0.73      1312
           1       0.83      0.78      0.80      1600

    accuracy                           0.76      3722
   macro avg       0.75      0.76      0.75      3722
weighted avg       0.76      0.76      0.76      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.33      0.49      0.39       810
           0       0.49      0.45      0.47      1312
           1       0.56      0.46      0.51      1600

    accuracy                           0.46      3722
   macro avg       0.46      0.47      0.46      3722
weighted avg       0.49      0.46      0.47      3722

Now plotting 38 days prediction in the future
i = 39
threshold = 0.02579
Now training 39 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 39 days prediction in the future
Now evaluating 39 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.54      0.66      0.59       798
           0       0.64      0.65      0.64      1325
           1       0.77      0.67      0.71      1599

    accuracy                           0.66      3722
   macro avg       0.65      0.66      0.65      3722
weighted avg       0.67      0.66      0.66      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.55      0.46       798
           0       0.54      0.49      0.51      1325
           1       0.65      0.57      0.60      1599

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.55      0.54      0.54      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.47      0.40       798
           0       0.48      0.47      0.48      1325
           1       0.56      0.47      0.51      1599

    accuracy                           0.47      3722
   macro avg       0.46      0.47      0.46      3722
weighted avg       0.49      0.47      0.48      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.50      0.36       798
           0       0.43      0.55      0.48      1325
           1       0.50      0.17      0.26      1599

    accuracy                           0.38      3722
   macro avg       0.40      0.41      0.36      3722
weighted avg       0.43      0.38      0.36      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.68      0.78      0.73       798
           0       0.77      0.75      0.76      1325
           1       0.85      0.80      0.82      1599

    accuracy                           0.78      3722
   macro avg       0.77      0.78      0.77      3722
weighted avg       0.78      0.78      0.78      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.31      0.51      0.38       798
           0       0.50      0.24      0.32      1325
           1       0.51      0.57      0.54      1599

    accuracy                           0.44      3722
   macro avg       0.44      0.44      0.41      3722
weighted avg       0.46      0.44      0.43      3722

Now plotting 39 days prediction in the future
i = 40
threshold = 0.026000000000000002
Now training 40 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 40 days prediction in the future
Now evaluating 40 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.53      0.69      0.60       799
           0       0.63      0.60      0.62      1314
           1       0.75      0.67      0.71      1609

    accuracy                           0.65      3722
   macro avg       0.64      0.66      0.64      3722
weighted avg       0.66      0.65      0.66      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.39      0.55      0.46       799
           0       0.51      0.53      0.52      1314
           1       0.66      0.51      0.57      1609

    accuracy                           0.52      3722
   macro avg       0.52      0.53      0.52      3722
weighted avg       0.55      0.52      0.53      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.47      0.40       799
           0       0.48      0.48      0.48      1314
           1       0.57      0.46      0.51      1609

    accuracy                           0.47      3722
   macro avg       0.46      0.47      0.46      3722
weighted avg       0.49      0.47      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.27      0.46      0.34       799
           0       0.43      0.55      0.48      1314
           1       0.51      0.20      0.29      1609

    accuracy                           0.38      3722
   macro avg       0.40      0.40      0.37      3722
weighted avg       0.43      0.38      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.66      0.82      0.73       799
           0       0.77      0.72      0.74      1314
           1       0.85      0.79      0.82      1609

    accuracy                           0.77      3722
   macro avg       0.76      0.78      0.77      3722
weighted avg       0.78      0.77      0.77      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.36      0.38      0.37       799
           0       0.46      0.57      0.51      1314
           1       0.59      0.45      0.51      1609

    accuracy                           0.48      3722
   macro avg       0.47      0.47      0.46      3722
weighted avg       0.49      0.48      0.48      3722

Now plotting 40 days prediction in the future
i = 41
threshold = 0.02619
Now training 41 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 30, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 10, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 41 days prediction in the future
Now evaluating 41 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.56      0.66      0.61       796
           0       0.65      0.62      0.64      1310
           1       0.76      0.72      0.74      1616

    accuracy                           0.67      3722
   macro avg       0.66      0.67      0.66      3722
weighted avg       0.68      0.67      0.67      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.52      0.44       796
           0       0.53      0.53      0.53      1310
           1       0.64      0.53      0.58      1616

    accuracy                           0.53      3722
   macro avg       0.52      0.53      0.52      3722
weighted avg       0.55      0.53      0.53      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.31      0.41      0.35       796
           0       0.45      0.45      0.45      1310
           1       0.55      0.46      0.50      1616

    accuracy                           0.44      3722
   macro avg       0.43      0.44      0.43      3722
weighted avg       0.46      0.44      0.45      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.53      0.38       796
           0       0.44      0.55      0.49      1310
           1       0.52      0.21      0.30      1616

    accuracy                           0.40      3722
   macro avg       0.42      0.43      0.39      3722
weighted avg       0.44      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.69      0.77      0.73       796
           0       0.74      0.72      0.73      1310
           1       0.83      0.81      0.82      1616

    accuracy                           0.77      3722
   macro avg       0.76      0.77      0.76      3722
weighted avg       0.77      0.77      0.77      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.55      0.42       796
           0       0.51      0.34      0.41      1310
           1       0.54      0.53      0.53      1616

    accuracy                           0.47      3722
   macro avg       0.46      0.47      0.45      3722
weighted avg       0.49      0.47      0.46      3722

Now plotting 41 days prediction in the future
i = 42
threshold = 0.026360000000000005
Now training 42 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 42 days prediction in the future
Now evaluating 42 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.58      0.68      0.62       795
           0       0.65      0.64      0.65      1296
           1       0.76      0.70      0.73      1631

    accuracy                           0.68      3722
   macro avg       0.66      0.67      0.67      3722
weighted avg       0.68      0.68      0.68      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.40      0.53      0.46       795
           0       0.53      0.52      0.52      1296
           1       0.65      0.56      0.60      1631

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.55      0.54      0.54      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.44      0.38       795
           0       0.47      0.46      0.46      1296
           1       0.56      0.47      0.51      1631

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.48      0.35       795
           0       0.42      0.56      0.48      1296
           1       0.53      0.20      0.29      1631

    accuracy                           0.39      3722
   macro avg       0.41      0.42      0.38      3722
weighted avg       0.44      0.39      0.37      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.67      0.78      0.72       795
           0       0.74      0.73      0.74      1296
           1       0.84      0.78      0.81      1631

    accuracy                           0.76      3722
   macro avg       0.75      0.77      0.76      3722
weighted avg       0.77      0.76      0.77      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.33      0.37      0.35       795
           0       0.46      0.50      0.48      1296
           1       0.56      0.49      0.52      1631

    accuracy                           0.47      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.48      0.47      0.47      3722

Now plotting 42 days prediction in the future
i = 43
threshold = 0.026510000000000002
Now training 43 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 43 days prediction in the future
Now evaluating 43 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.55      0.66      0.60       796
           0       0.63      0.65      0.64      1284
           1       0.77      0.68      0.72      1642

    accuracy                           0.66      3722
   macro avg       0.65      0.66      0.65      3722
weighted avg       0.67      0.66      0.67      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.40      0.54      0.46       796
           0       0.51      0.54      0.53      1284
           1       0.68      0.54      0.60      1642

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.56      0.54      0.55      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.43      0.37       796
           0       0.47      0.47      0.47      1284
           1       0.57      0.47      0.52      1642

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.30      0.49      0.37       796
           0       0.42      0.59      0.49      1284
           1       0.54      0.20      0.29      1642

    accuracy                           0.40      3722
   macro avg       0.42      0.43      0.38      3722
weighted avg       0.45      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.69      0.81      0.74       796
           0       0.75      0.73      0.74      1284
           1       0.84      0.78      0.81      1642

    accuracy                           0.77      3722
   macro avg       0.76      0.78      0.77      3722
weighted avg       0.78      0.77      0.77      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.33      0.47      0.39       796
           0       0.49      0.42      0.45      1284
           1       0.57      0.51      0.54      1642

    accuracy                           0.47      3722
   macro avg       0.46      0.47      0.46      3722
weighted avg       0.49      0.47      0.48      3722

Now plotting 43 days prediction in the future
i = 44
threshold = 0.026639999999999997
Now training 44 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 44 days prediction in the future
Now evaluating 44 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.55      0.62      0.59       792
           0       0.62      0.65      0.63      1276
           1       0.77      0.69      0.73      1654

    accuracy                           0.66      3722
   macro avg       0.65      0.65      0.65      3722
weighted avg       0.67      0.66      0.66      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.56      0.46       792
           0       0.51      0.48      0.50      1276
           1       0.67      0.54      0.60      1654

    accuracy                           0.53      3722
   macro avg       0.52      0.53      0.52      3722
weighted avg       0.55      0.53      0.53      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.36      0.49      0.41       792
           0       0.46      0.46      0.46      1276
           1       0.57      0.46      0.51      1654

    accuracy                           0.47      3722
   macro avg       0.46      0.47      0.46      3722
weighted avg       0.49      0.47      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.30      0.48      0.37       792
           0       0.40      0.57      0.47      1276
           1       0.54      0.21      0.31      1654

    accuracy                           0.39      3722
   macro avg       0.41      0.42      0.38      3722
weighted avg       0.44      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.67      0.79      0.73       792
           0       0.75      0.73      0.74      1276
           1       0.83      0.79      0.81      1654

    accuracy                           0.77      3722
   macro avg       0.75      0.77      0.76      3722
weighted avg       0.77      0.77      0.77      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.53      0.42       792
           0       0.48      0.45      0.46      1276
           1       0.57      0.46      0.51      1654

    accuracy                           0.47      3722
   macro avg       0.47      0.48      0.47      3722
weighted avg       0.49      0.47      0.48      3722

Now plotting 44 days prediction in the future
i = 45
threshold = 0.02675
Now training 45 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 5, 'KNN__weights': 'distance'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 45 days prediction in the future
Now evaluating 45 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.56      0.64      0.60       794
           0       0.64      0.63      0.63      1267
           1       0.76      0.72      0.74      1661

    accuracy                           0.67      3722
   macro avg       0.65      0.66      0.66      3722
weighted avg       0.68      0.67      0.67      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.57      0.46       794
           0       0.52      0.48      0.50      1267
           1       0.66      0.54      0.59      1661

    accuracy                           0.53      3722
   macro avg       0.52      0.53      0.52      3722
weighted avg       0.55      0.53      0.53      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.33      0.48      0.39       794
           0       0.46      0.44      0.45      1267
           1       0.58      0.46      0.51      1661

    accuracy                           0.46      3722
   macro avg       0.45      0.46      0.45      3722
weighted avg       0.48      0.46      0.46      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.43      0.34       794
           0       0.40      0.55      0.46      1267
           1       0.53      0.25      0.34      1661

    accuracy                           0.39      3722
   macro avg       0.41      0.41      0.38      3722
weighted avg       0.43      0.39      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.67      0.77      0.72       794
           0       0.74      0.70      0.72      1267
           1       0.83      0.80      0.82      1661

    accuracy                           0.76      3722
   macro avg       0.75      0.76      0.75      3722
weighted avg       0.77      0.76      0.76      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.32      0.51      0.39       794
           0       0.46      0.42      0.44      1267
           1       0.57      0.44      0.50      1661

    accuracy                           0.45      3722
   macro avg       0.45      0.46      0.44      3722
weighted avg       0.48      0.45      0.45      3722

Now plotting 45 days prediction in the future
i = 46
threshold = 0.02684
Now training 46 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 0.01, 'Logistic__solver': 'lbfgs'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 46 days prediction in the future
Now evaluating 46 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.59      0.68      0.63       791
           0       0.64      0.67      0.65      1255
           1       0.78      0.69      0.73      1676

    accuracy                           0.68      3722
   macro avg       0.67      0.68      0.67      3722
weighted avg       0.69      0.68      0.69      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.40      0.53      0.46       791
           0       0.53      0.49      0.51      1255
           1       0.66      0.60      0.63      1676

    accuracy                           0.55      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.56      0.55      0.55      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.45      0.39       791
           0       0.45      0.48      0.46      1255
           1       0.57      0.47      0.52      1676

    accuracy                           0.47      3722
   macro avg       0.46      0.46      0.46      3722
weighted avg       0.48      0.47      0.47      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.30      0.46      0.36       791
           0       0.41      0.58      0.48      1255
           1       0.55      0.25      0.34      1676

    accuracy                           0.40      3722
   macro avg       0.42      0.43      0.40      3722
weighted avg       0.45      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.68      0.81      0.74       791
           0       0.76      0.74      0.75      1255
           1       0.85      0.79      0.82      1676

    accuracy                           0.78      3722
   macro avg       0.76      0.78      0.77      3722
weighted avg       0.78      0.78      0.78      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.35      0.57      0.43       791
           0       0.47      0.52      0.49      1255
           1       0.63      0.39      0.48      1676

    accuracy                           0.47      3722
   macro avg       0.48      0.49      0.47      3722
weighted avg       0.52      0.47      0.48      3722

Now plotting 46 days prediction in the future
i = 47
threshold = 0.02691
Now training 47 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': 20, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 47 days prediction in the future
Now evaluating 47 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.57      0.68      0.62       788
           0       0.61      0.66      0.63      1253
           1       0.79      0.67      0.73      1681

    accuracy                           0.67      3722
   macro avg       0.66      0.67      0.66      3722
weighted avg       0.68      0.67      0.67      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.38      0.56      0.46       788
           0       0.49      0.51      0.50      1253
           1       0.68      0.50      0.58      1681

    accuracy                           0.52      3722
   macro avg       0.52      0.53      0.51      3722
weighted avg       0.55      0.52      0.53      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.46      0.39       788
           0       0.47      0.48      0.47      1253
           1       0.60      0.49      0.54      1681

    accuracy                           0.48      3722
   macro avg       0.47      0.47      0.47      3722
weighted avg       0.50      0.48      0.48      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.29      0.47      0.36       788
           0       0.41      0.57      0.48      1253
           1       0.57      0.23      0.32      1681

    accuracy                           0.40      3722
   macro avg       0.42      0.42      0.39      3722
weighted avg       0.46      0.40      0.38      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.69      0.79      0.73       788
           0       0.74      0.75      0.74      1253
           1       0.86      0.80      0.83      1681

    accuracy                           0.78      3722
   macro avg       0.76      0.78      0.77      3722
weighted avg       0.78      0.78      0.78      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.33      0.55      0.41       788
           0       0.44      0.49      0.47      1253
           1       0.65      0.39      0.49      1681

    accuracy                           0.46      3722
   macro avg       0.47      0.48      0.45      3722
weighted avg       0.51      0.46      0.46      3722

Now plotting 47 days prediction in the future
i = 48
threshold = 0.026959999999999998
Now training 48 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 100, 'Logistic__solver': 'newton-cg'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 48 days prediction in the future
Now evaluating 48 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.56      0.66      0.61       791
           0       0.62      0.66      0.64      1240
           1       0.79      0.68      0.73      1691

    accuracy                           0.67      3722
   macro avg       0.66      0.67      0.66      3722
weighted avg       0.68      0.67      0.67      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.37      0.54      0.44       791
           0       0.51      0.48      0.49      1240
           1       0.69      0.57      0.62      1691

    accuracy                           0.53      3722
   macro avg       0.52      0.53      0.52      3722
weighted avg       0.56      0.53      0.54      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.35      0.48      0.40       791
           0       0.46      0.47      0.46      1240
           1       0.59      0.49      0.54      1691

    accuracy                           0.48      3722
   macro avg       0.47      0.48      0.47      3722
weighted avg       0.50      0.48      0.48      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.28      0.43      0.34       791
           0       0.41      0.58      0.48      1240
           1       0.55      0.25      0.34      1691

    accuracy                           0.40      3722
   macro avg       0.41      0.42      0.39      3722
weighted avg       0.45      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.68      0.77      0.72       791
           0       0.74      0.73      0.74      1240
           1       0.86      0.81      0.83      1691

    accuracy                           0.78      3722
   macro avg       0.76      0.77      0.76      3722
weighted avg       0.78      0.78      0.78      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.34      0.48      0.40       791
           0       0.44      0.50      0.47      1240
           1       0.60      0.42      0.50      1691

    accuracy                           0.46      3722
   macro avg       0.46      0.47      0.45      3722
weighted avg       0.49      0.46      0.47      3722

Now plotting 48 days prediction in the future
i = 49
threshold = 0.02699
Now training 49 days prediction in the future
['model_DecisionTree', 'model_GradientBoosting', 'model_KNN', 'model_Logistic', 'model_RandomForest', 'model_SVC']
Fitting 5 folds for each of 12 candidates, totalling 60 fits
{'DT__max_depth': None, 'DT__min_samples_split': 2}
Fitting 3 folds for each of 8 candidates, totalling 24 fits
{'GradientBoosting__learning_rate': 0.2, 'GradientBoosting__max_depth': 5, 'GradientBoosting__n_estimators': 4}
Fitting 5 folds for each of 10 candidates, totalling 50 fits
{'KNN__n_neighbors': 1, 'KNN__weights': 'uniform'}
Fitting 5 folds for each of 15 candidates, totalling 75 fits
{'Logistic__C': 1, 'Logistic__solver': 'liblinear'}
Fitting 3 folds for each of 4 candidates, totalling 12 fits
{'RandomForest__max_depth': 20, 'RandomForest__n_estimators': 100}
Fitting 3 folds for each of 6 candidates, totalling 18 fits
{'SVC__C': 10, 'SVC__kernel': 'rbf'}
Now finishing training 49 days prediction in the future
Now evaluating 49 days prediction in the future
model_DecisionTree
              precision    recall  f1-score   support

          -1       0.56      0.68      0.62       795
           0       0.63      0.63      0.63      1220
           1       0.79      0.72      0.75      1707

    accuracy                           0.68      3722
   macro avg       0.66      0.68      0.67      3722
weighted avg       0.69      0.68      0.68      3722

model_GradientBoosting
              precision    recall  f1-score   support

          -1       0.42      0.54      0.47       795
           0       0.51      0.47      0.49      1220
           1       0.65      0.60      0.62      1707

    accuracy                           0.54      3722
   macro avg       0.53      0.54      0.53      3722
weighted avg       0.56      0.54      0.55      3722

model_KNN
              precision    recall  f1-score   support

          -1       0.34      0.45      0.39       795
           0       0.44      0.44      0.44      1220
           1       0.59      0.50      0.54      1707

    accuracy                           0.47      3722
   macro avg       0.46      0.46      0.46      3722
weighted avg       0.49      0.47      0.48      3722

model_Logistic
              precision    recall  f1-score   support

          -1       0.31      0.45      0.37       795
           0       0.39      0.58      0.47      1220
           1       0.55      0.25      0.35      1707

    accuracy                           0.40      3722
   macro avg       0.42      0.43      0.39      3722
weighted avg       0.45      0.40      0.39      3722

model_RandomForest
              precision    recall  f1-score   support

          -1       0.69      0.82      0.75       795
           0       0.75      0.73      0.74      1220
           1       0.86      0.81      0.83      1707

    accuracy                           0.78      3722
   macro avg       0.77      0.78      0.77      3722
weighted avg       0.79      0.78      0.78      3722

model_SVC
              precision    recall  f1-score   support

          -1       0.36      0.39      0.38       795
           0       0.42      0.47      0.45      1220
           1       0.56      0.49      0.52      1707

    accuracy                           0.46      3722
   macro avg       0.45      0.45      0.45      3722
weighted avg       0.47      0.46      0.47      3722

Now plotting 49 days prediction in the future